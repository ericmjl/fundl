{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "/home/ericmjl/anaconda/envs/fundl-dev/lib/python3.7/site-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 7604 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundl.datasets import make_graph_counting_dataset\n",
    "from fundl.utils import pad_graph\n",
    "import numpy as onp\n",
    "import networkx as nx\n",
    "import jax.numpy as np\n",
    "from chemgraph import atom_graph\n",
    "import janitor.chemistry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature matrices and adjacency matrices...\n",
      "Preparing outputs...\n",
      "Padding graphs to correct size...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = (\n",
    "    pd.read_csv(\"bace.csv\")\n",
    "    .rename_column(\"mol\", \"structure\")\n",
    "    .smiles2mol(\"structure\", \"mol\")\n",
    "    .join_apply(lambda x: atom_graph(x[\"mol\"]), \"graph\")\n",
    "    .join_apply(lambda x: len(x[\"graph\"]), \"graph_size\")\n",
    ")\n",
    "\n",
    "Gs = df[\"graph\"].tolist()\n",
    "\n",
    "print(\"Generating feature matrices and adjacency matrices...\")\n",
    "Fs = []\n",
    "As = []\n",
    "for G in Gs:\n",
    "    Fs.append(onp.vstack([d[\"features\"] for n, d in G.nodes(data=True)]))\n",
    "    As.append(onp.asarray(nx.adjacency_matrix(G).todense()))\n",
    "\n",
    "largest_graph_size = max([len(G) for G in Gs])\n",
    "\n",
    "print(\"Preparing outputs...\")\n",
    "# Next line is a dummy task, count number of nodes in graph.\n",
    "# y = np.array([len(G) for G in Gs]).reshape(-1, 1)\n",
    "\n",
    "# Next line is a real task.\n",
    "y = df[\"pIC50\"].values.reshape(-1, 1)\n",
    "\n",
    "print(\"Padding graphs to correct size...\")\n",
    "for i, (F, A) in enumerate(zip(Fs, As)):\n",
    "    F, A = pad_graph(F, A, largest_graph_size)\n",
    "    Fs[i] = F\n",
    "    As[i] = A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5445461, 10.522879)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1513, 97, 9)\n",
      "(1513, 97, 97)\n"
     ]
    }
   ],
   "source": [
    "Fs = onp.stack(Fs).astype(float)\n",
    "As = onp.stack(As).astype(float)\n",
    "\n",
    "print(Fs.shape)\n",
    "print(As.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundl.activations import relu\n",
    "\n",
    "def dense_params(prefix, input_dim, output_dim):\n",
    "    w = pm.Normal(f\"{prefix}_w\", mu=0, sigma=0.1, shape=(input_dim, output_dim))\n",
    "    b = pm.Normal(f\"{prefix}_b\", mu=0, sigma=0.1, shape=(output_dim,))\n",
    "    return dict(w=w, b=b)\n",
    "\n",
    "def mpnn(params, A, F, nonlin=relu):\n",
    "    \"\"\"Follow semantics of fundl.layers.graph.mpnn\"\"\"\n",
    "    F = tt.batched_dot(A, F)\n",
    "    F = tt.dot(F, params[\"w\"]) + params[\"b\"]\n",
    "    return nonlin(F)\n",
    "\n",
    "\n",
    "def gather(F):\n",
    "    \"\"\"Follow semantics of fundl.layers.graph.gather\"\"\"\n",
    "    return tt.sum(F, axis=1)\n",
    "\n",
    "def dense(params, x, nonlin=relu):\n",
    "    \"\"\"Follow semantics of fundl.layers.dense\"\"\"\n",
    "    a = nonlin(tt.dot(x, params[\"w\"]) + params[\"b\"])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Priors on parameters.\n",
    "    params = dict()\n",
    "    params[\"graph1\"] = dense_params(\"graph1\", 9, 9)\n",
    "    params[\"graph2\"] = dense_params(\"graph2\", 9, 5)\n",
    "    params[\"dense1\"] = dense_params(\"dense1\", 5, 5)\n",
    "    params[\"dense2\"] = dense_params(\"dense2\", 5, 1)\n",
    "    \n",
    "    acts1 = mpnn(params[\"graph1\"], As, Fs)\n",
    "    acts2 = mpnn(params[\"graph2\"], As, acts1)\n",
    "    out = gather(acts2)\n",
    "    out = dense(params[\"dense1\"], out)\n",
    "    out = dense(params[\"dense2\"], out)\n",
    "    \n",
    "    # Prior on noise in measurement.\n",
    "    sd = pm.Exponential(\"sd\", lam=1)\n",
    "    \n",
    "    # Likelihood\n",
    "    like = pm.Normal(\"like\", mu=out, sd=sd, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 4,075.4:  13%|â–ˆâ–        | 63888/500000 [47:09<5:13:53, 23.16it/s]   "
     ]
    }
   ],
   "source": [
    "with model:\n",
    "#     trace_nuts = pm.sample(2000, cores=1)\n",
    "    approx = pm.fit(n=500000)\n",
    "    trace = approx.sample(2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace[\"graph1_w\"].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    samples = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(approx.hist)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, m, u = np.percentile(samples[\"like\"], q=[25, 50, 75], axis=0)\n",
    "\n",
    "ldiff = m - l\n",
    "udiff = u - m\n",
    "\n",
    "# plt.errorbar(\n",
    "#     y, \n",
    "#     samples[\"like\"].mean(axis=0),\n",
    "#     yerr=[ldiff, udiff],\n",
    "#     marker='o'\n",
    "# )\n",
    "plt.scatter(y, samples[\"like\"].mean(axis=0), color='red')\n",
    "\n",
    "\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks off by a factor of a few hundred, but sure, I think I can dig that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundl-dev",
   "language": "python",
   "name": "fundl-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
