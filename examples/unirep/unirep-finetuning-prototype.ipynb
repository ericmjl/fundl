{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unirep_reimplementation import aa_seq_to_int, aa_to_int, one_hots\n",
    "import jax.numpy as np\n",
    "from fundl.layers.rnn import mlstm1900\n",
    "from fundl.weights import add_dense_params\n",
    "from fundl.layers import dense\n",
    "from fundl.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"MRKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFARYPDHMKQHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\",\n",
    "    \"MRKGEELFTGVVPILVELDGDVGGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFARYPDHMKQHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\",\n",
    "    \"MRKGEELFTGVVPILVELDGDVGGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFARYPDEMKQHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\",\n",
    "]\n",
    "next_letters = [s[1:] for s in sequences]\n",
    "\n",
    "sequences_int = [aa_seq_to_int(s) for s in sequences]\n",
    "next_letters_int = [aa_seq_to_int(s) for s in next_letters]\n",
    "\n",
    "embeddings = np.load(\"1900_weights/embed_matrix:0.npy\")\n",
    "x = np.stack([embeddings[i] for i in sequences_int], axis=0)[:, :-1, :]\n",
    "y = np.stack([one_hots[i] for i in next_letters_int], axis=0)\n",
    "\n",
    "# x = sliding_window(sequence, size=10)\n",
    "params = dict()\n",
    "params[\"unirep\"] = dict()\n",
    "params[\"unirep\"][\"gh\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_gh:0.npy\")\n",
    "params[\"unirep\"][\"gmh\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_gmh:0.npy\")\n",
    "params[\"unirep\"][\"gmx\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_gmx:0.npy\")\n",
    "params[\"unirep\"][\"gx\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_gx:0.npy\")\n",
    "\n",
    "params[\"unirep\"][\"wh\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_wh:0.npy\")\n",
    "params[\"unirep\"][\"wmh\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_wmh:0.npy\")\n",
    "params[\"unirep\"][\"wmx\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_wmx:0.npy\")\n",
    "params[\"unirep\"][\"wx\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_wx:0.npy\")\n",
    "\n",
    "params[\"unirep\"][\"b\"] = np.load(\"1900_weights/rnn_mlstm_mlstm_b:0.npy\")\n",
    "\n",
    "params = add_dense_params(params, \"dense\", 1900, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_sequence_model(params, x):\n",
    "    \"\"\"\n",
    "    This model predicts next sequence.\n",
    "    \n",
    "    x.shape: (:, length_of_sequence, 10)\n",
    "\n",
    "    output shape:\n",
    "        (:, length_of_sequence, 20)\n",
    "        The (:) dimension is the sample dimension.\n",
    "        The data cube should be compared against a binary-valued tensor\n",
    "        that contains the truth.\n",
    "    \"\"\"\n",
    "    x = mlstm1900(params[\"unirep\"], x)\n",
    "    x = dense(params[\"dense\"], x, nonlin=sigmoid)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "out = next_sequence_model(params, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundl.losses import neg_cross_entropy_loss\n",
    "from functools import partial\n",
    "from jax import grad, jit\n",
    "\n",
    "loss = partial(neg_cross_entropy_loss, model=next_sequence_model)\n",
    "\n",
    "loss(params, x=x, y=y)\n",
    "dloss = jit(grad(loss))\n",
    "g = dloss(params, x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.optimizers import adam\n",
    "\n",
    "init, update, get_params = adam(step_size=0.005)\n",
    "\n",
    "state = init(params)\n",
    "for i in range(100):\n",
    "    g = dloss(params, x=x, y=y)\n",
    "    l = loss(params, x=x, y=y)\n",
    "\n",
    "    state = update(i, g, state)\n",
    "    params = get_params(state)\n",
    "\n",
    "    print(i, l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundl-dev",
   "language": "python",
   "name": "fundl-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
